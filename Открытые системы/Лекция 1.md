Система - некая совокупность элементов, которая обладает бОльшим функционалом, чем ее элементы по отдельности.

Открытые системы - системы которые взаимодействуют и обмениваются чем-либо с внешней средой.

Иронично, что этим хоть и занимаются, но как таковых конкретных учебников нет.

### Литература
Мурзилка (метода) - "Открытые системы. Тексты лекций"
Еще интересная литература - Андрей Робачевский, "Опреационная система UNIX" (написана)

### Н
Открытые системы в области информатики - это, например, интернет, т.к. выполняются все условия из определения выше. Так же такими системами являются UNIX-системы (но у них нет открытого исходника) и GNU/Linux системы (GNU= 'GNU Not UNIX', придумана Ричардом Стоуманом)

Линус Торвальдс хотел учиться из дома, но дома не было нужной UNIX-системы, по этому он придумал свою - Linux.

Что будет на курсе:
* Общая база про открытые информационные системы
* Спецификации открытых систем (например, для создания производных открытых систем более высокого уровня)
* Немного про интернет
* Лицензирование открытых систем (например, публикация исходников - важная часть открытости)

## ОТКРЫТЫЕ СИСТЕМЫ

Говорят, что система открыта к расширению/изменению ее функционалу.
Системы так же открыты к соединению 

Одним из популярных вариантов взаимодействия является OSI (Open Systems Interconnection)

Чтобы модуль был модулем, нужно, чтобы он соответствовал спецификациям и мог без проблем взаимодействовать с другими модулями в соответствии со стандартами.

Тогда модульная система вполне  считается открытой

Стандарты - это в целом круто (и глобально удобно), но его проблема в том, что ты не можешь его нарушить. А это уже препятствие к прогрессу. А пересмотреть стандарты могут только те, кто их контролирует. Контра такому нюансу - это открытые стандарты, которые контролируются и правятся людьми извне, грубо говоря.

И открытые системы как раз соблюдают открытые стандарты.
POSIX (Portable Operating System Interface) - это семейство стандартов для открытых систем, чтоб оно все могло работать вместе. Наприме, API облада

Открытая система - это система, которая реализует **открытые спецификации** на интерфейсы, сервисы (услуги среды) и поддерживаемые форматы данных, достаточные для того, чтобы дать возможность должным образом разработанному прикладному программному обеспечению быть переносимым в широком диапазоне систем с минимальными изменениями, взаимодействовать с другими приложениями на локальных и удалённых системах, и взаимодействовать с пользователями в стиле, который облегчает переход пользователей от системы к системе.

Только открытые системы позволяют максимально продуктивно тратить ресурсы на поддержание системы. Интернет ресурсы как раз, в подавляющем большинстве, работают на открытых системах, так что с ними можно взаимодействовать до сих пор.

### История становления открытых систем

Как известно, ЭВМ были крайне дорогими. Казалось бы, их можно продавать (в частности их мощности), но до этого дошли только в 1960-х, когда поняли, что это возможно (до этого, как и ожидалось, всеми мощностями пользовались только военные).

Для пользования компами по началу писали проги на двоичном коде, потом все дошло до написания ЯП, что привело к понятию трансляции.

Проги писали, железо устаревало, тогда вопрос - а что делать с программой? Ее ты на другой комп хрен перенесешь, т.к. каждый комп был, по сути дела, уникальным. Даже команды были разными. Контрой стали программы-трансляторы с высокоуровневого ЯП. Потребность в экономии на разработке и поддержании ПО привело как раз к идее разработки открытых систем. Она должна позволять использовать раннее написанные программы на других системах.

И этим начали заниматься IBM. Они же и ввели понятие архитектуры

/ОРГАНИЗАЦИЯ ЭВМ != АРХИТЕКТУРА ЭВМ/

Организация - это то, как устроен ЭВМ, какие в нем железки. Для внешнего пользователя (для которого ПК - черный ящик) будет только разница в скорости. Можно собрать много разных компов. Но они все будут одной архитектуры: у них одинаковые наборы программ, инструкций. Это позволяло компьютерам прогрессировать (менять организацию), но программы, написанные ранее, все равно работали так же (сохранять архитектуру)

Второе, что сделали IBM - придумали виртуализацию (памяти - устр-ва, хранящего данные -  в частности).
У памяти, как известно, есть ограничения в объеме (оно обусловлено шиной адреса). Забавно, процессоры у нас 64-х битные, но они урезаны до 48 бит (физически до сих пор не смогли преодолеть рубеж). Но программисты могут использовать ВИРТУАЛЬНЫЕ 64 бит. Просто они сначала урезаются до 48 имеющихся физически, а остальные просто лежат в очереди. Вот такая вот хуйня)

По факту, можно виртуализировать что угодно. Например, можно виртуализировать процессор для работы с числами с плавающей запятой (хотя чисто физически процессор мог и не уметь ими оперировать).

Виртуализация изначально заключалась в подключении модулей в сокеты, но начиная с 486 процессора удалось интегрировать сопроцессор для вирутализации.

Но вопрос, как виртуализировать память (в частноти, внешнюю).
* Внешняя память должна быть энергонезависимой (хранить данные независимо от того, работает комп или нет)
	* Процессор может выполнять только команды из основной (оперативной) памяти. Но вот на нее информация может попадать как раз с внешней.
	* Для этого часть внешней памяти делали постоянной. Туда записывались те команды, которые инициализировались при запуске ПК. (привет, биос)
	* Во внешней памяти мы не можем обратиться к памяти по адресу.
	* RAM (Random Access Memory) - это как раз таки ОЗУ (мы можем именно что обратиться к конкретной ячейке по памяти). В ней, например, делали последовательный доступ (она читалась в одном направлении, но если тебе нужно было перейти назад, то ты вписал бы инструкцию о перемотке назад). Время доступа к памяти не зависит от адреса.
	* DAM (Direct Access Memory) - в такой памяти мы сразу читаем целый блок данных (например, 512 байт). Даже если тебе нужен был один конкретный байт, то тебе нужно было именно весь блок перезаписывать. В отличии от RAM, тут время доступа к памяти зависит от адреса.

По итогу все пришло к единой спецификации данных на внешних устройствах.

...

Одно из фундаментальных понятий в информатике - понятие файла. Причем, файл на UNIX-системах и файл на Windows - это нихуя не одинаковая хуйня.

BSD (Berkeley Software Distribution) - один из видов СУФ.

Системное ПО (оно же СУФ - Система управления файлами) вводила еще метаданные, которые по имени файла могло дать доступ к данным. И таких систем просто дохуя.
И только примерно 10 из них наиболее распространены (например, NTFS, которая делает разметку диска, деля диск на две части: системная и область хранения данных) Форматирование диска как раз и заключается в этом делении. 

!И ЭТА ХУЙНЯ ЕЩЕ ПРОСТАЯ!

Итог - блочное деление данных хуйня галимая. Вместо них придумали кластеры - группа соседних блоков, кол-во которых кратно степени двойки. Например, размер кластера 8кБайт. Тогда файл меньше размера кластера будет занимать весь кластер. Но для больших файлов, наоборот, лучше использовать бОльшие кластеры.

Тогда решили усложнить разметку диска - в каждой части использовать свою файловую систему. Так и появилось разбиение одного физического диска на несколько виртуальных.


